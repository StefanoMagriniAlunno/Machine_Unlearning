{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Unlearning\n",
        "\n",
        "Can you unlearn something?\n",
        "\n",
        "Your task here is the following: given a network pre-trained on some data, you want to finetune it to selectively forget a class, and learn a new class.\n",
        "\n",
        "As an initial approach, you may do the following.\n",
        "\n",
        "Start with a MNIST classifier pre-trained on a subset of the\n",
        "digits.\n",
        "\n",
        "Now replace one of the learned digits, say the class \u201c6\u201d, with a new digit, say \u201c3\u201d.\n",
        "\n",
        "A possible way to proceed is to identify which weights are more involved in the prediction of class \u201c6\u201d, freeze all the rest, and train with a loss that favors the \u201c3\u201d while penalizing the \u201c6\u201d.\n",
        "\n",
        "Test this baseline and see whether it brings you anywhere. Are there any pitfalls in this idea? Does it work? Use it as a first line of attack to understand the problem.\n",
        "\n",
        "Starting from these baseline tests, devise a new unlearning procedure.\n",
        "\n",
        "You can improve upon this baseline, make up your own idea from scratch, or check the literature to get ideas.\n",
        "\n",
        "If you use an existing approach, you must add something new, for example by testing it on some new data modality (e.g., audio), by studying more extreme cases, failures, weaknesses, or by making it more efficient, and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HOW TO TRAIN A MODEL\n",
        "\n",
        "# select a template from source.template:\n",
        "#from source.template.EMNIST import main\n",
        "#main(20, 10, 256, 'data/models/EMNIST')\n",
        "\n",
        "from source.template.Cifar10 import main\n",
        "main(8, 30, 512, 'data/models/Cifar10')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EMNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LOAD A MODEL\n",
        "import torch\n",
        "import os\n",
        "from source.template.EMNIST import Classifier\n",
        "from source.template.EMNIST import N_CLASSES\n",
        "import random\n",
        "\n",
        "model_path = \"data/models/EMNIST/5_38_10_29_7_27_26_42_9_16_2_33_3_14_39_40_32_11_45_23.pt\"\n",
        "original_list_classes = [int(c) for c in os.path.splitext(os.path.basename(model_path))[0].split('_')]\n",
        "n_classes = len(original_list_classes)\n",
        "\n",
        "model = Classifier(n_classes)\n",
        "model.load_state_dict(torch.load(model_path, weights_only=True))\n",
        "\n",
        "# seleziono una old_class a caso da list_classes\n",
        "old_class = random.choice(original_list_classes)\n",
        "# ottengo la new_class (un numero in range(N_CLASSES) non in list_classes)\n",
        "new_class = random.choice([i for i in range(N_CLASSES) if i not in original_list_classes])\n",
        "# sostituisco old_class con new_class in list_classes\n",
        "list_classes = original_list_classes.copy()\n",
        "list_classes[list_classes.index(old_class)] = new_class\n",
        "\n",
        "print(\"Classi originali:      \", original_list_classes)\n",
        "print(\"Classi da memorizzare: \", list_classes)\n",
        "print(\"Classi da dimenticare: \", old_class, f\" (sostituita da {new_class})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAKE DATALOADER\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from source.template.EMNIST import SPLIT, FilterSet\n",
        "\n",
        "loader = torch.utils.data.DataLoader(\n",
        "    FilterSet(\n",
        "        torchvision.datasets.EMNIST(\n",
        "            root=\"data/db\",\n",
        "            split=SPLIT,\n",
        "            train=True,\n",
        "            download=True,\n",
        "            transform=transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Grayscale(),\n",
        "                    transforms.Pad(2),  # pad to 32x32\n",
        "                    transforms.RandomAffine(\n",
        "                        degrees=5,\n",
        "                        translate=(0.1, 0.1),\n",
        "                        scale=(0.9, 1.1),\n",
        "                        shear=10\n",
        "                    ),\n",
        "                    transforms.ColorJitter(contrast=(0.9,1.5)),\n",
        "                ]\n",
        "            ),\n",
        "            target_transform=lambda x: list_classes.index(x) if x in list_classes else -1\n",
        "        ),\n",
        "        torch.tensor(list_classes + [old_class]),\n",
        "    ),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TEST LOADER\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    FilterSet(\n",
        "        torchvision.datasets.EMNIST(\n",
        "            root=\"data/db\",\n",
        "            split=SPLIT,\n",
        "            train=False,\n",
        "            download=True,\n",
        "            transform=transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Grayscale(),\n",
        "                    transforms.Pad(2),  # pad to 32x32\n",
        "                ]\n",
        "            ),\n",
        "            target_transform=lambda x: list_classes.index(x) if x in list_classes else -1\n",
        "        ),\n",
        "        torch.tensor(list_classes + [old_class]),\n",
        "    ),\n",
        "    batch_size=512,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cifar10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LOAD A MODEL\n",
        "import torch\n",
        "import os\n",
        "from source.template.Cifar10 import Classifier\n",
        "from source.template.Cifar10 import N_CLASSES\n",
        "import random\n",
        "\n",
        "model_path = \"data/models/Cifar10/7_5_8_1_9_6_2_3.pt\"\n",
        "original_list_classes = [int(c) for c in os.path.splitext(os.path.basename(model_path))[0].split('_')]\n",
        "n_classes = len(original_list_classes)\n",
        "\n",
        "model = Classifier(n_classes)\n",
        "model.load_state_dict(torch.load(model_path, weights_only=True))\n",
        "\n",
        "# seleziono una old_class a caso da list_classes\n",
        "old_class = random.choice(original_list_classes)\n",
        "# ottengo la new_class (un numero in range(N_CLASSES) non in list_classes)\n",
        "new_class = random.choice([i for i in range(N_CLASSES) if i not in original_list_classes])\n",
        "# sostituisco old_class con new_class in list_classes\n",
        "list_classes = original_list_classes.copy()\n",
        "list_classes[list_classes.index(old_class)] = new_class\n",
        "\n",
        "print(\"Classi originali:      \", original_list_classes)\n",
        "print(\"Classi da memorizzare: \", list_classes)\n",
        "print(\"Classi da dimenticare: \", old_class, f\" (sostituita da {new_class})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAKE DATALOADER\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from source.template.Cifar10 import FilterSet\n",
        "\n",
        "loader = torch.utils.data.DataLoader(\n",
        "    FilterSet(\n",
        "        torchvision.datasets.CIFAR10(\n",
        "            root=\"data/db\",\n",
        "            train=True,\n",
        "            download=True,\n",
        "            transform=transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
        "                transforms.RandomAffine(\n",
        "                    degrees=0,\n",
        "                    scale=(1.0, 1.1),\n",
        "                    shear=0\n",
        "                ),\n",
        "                transforms.ColorJitter(\n",
        "                    contrast=(0.9,1.5),\n",
        "                    saturation=(0.9,1.3),\n",
        "                    brightness=(0.9,1.3),\n",
        "                    hue=(-0.05,0.05),\n",
        "                ),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
        "            ]),\n",
        "            target_transform=lambda x: list_classes.index(x) if x in list_classes else -1\n",
        "        ),\n",
        "        torch.tensor(list_classes + [old_class]),\n",
        "    ),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TEST LOADER\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    FilterSet(\n",
        "        torchvision.datasets.CIFAR10(\n",
        "            root=\"data/db\",\n",
        "            train=False,\n",
        "            download=True,\n",
        "            transform=transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
        "                ]\n",
        "            ),\n",
        "            target_transform=lambda x: list_classes.index(x) if x in list_classes else -1\n",
        "        ),\n",
        "        torch.tensor(list_classes + [old_class]),\n",
        "    ),\n",
        "    batch_size=512,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SST-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "/home/stefano/Documents/GitHub/Machine_Unlearning/.venv/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SST2\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Carica il dataset\u001b[39;00m\n\u001b[1;32m      5\u001b[0m train_data, test_data \u001b[38;5;241m=\u001b[39m SST2(\n\u001b[1;32m      6\u001b[0m     root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/db\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m )\n",
            "File \u001b[0;32m~/Documents/GitHub/Machine_Unlearning/.venv/lib/python3.10/site-packages/torchtext/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m     _WARN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     20\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "File \u001b[0;32m~/Documents/GitHub/Machine_Unlearning/.venv/lib/python3.10/site-packages/torchtext/_extension.py:64\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43m_init_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/GitHub/Machine_Unlearning/.venv/lib/python3.10/site-packages/torchtext/_extension.py:58\u001b[0m, in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mod_utils\u001b[38;5;241m.\u001b[39mis_module_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext._torchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext C++ Extension is not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n",
            "File \u001b[0;32m~/Documents/GitHub/Machine_Unlearning/.venv/lib/python3.10/site-packages/torchtext/_extension.py:50\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/GitHub/Machine_Unlearning/.venv/lib/python3.10/site-packages/torch/_ops.py:1295\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1290\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m-> 1295\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
            "File \u001b[0;32m/usr/lib/python3.10/ctypes/__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
            "\u001b[0;31mOSError\u001b[0m: /home/stefano/Documents/GitHub/Machine_Unlearning/.venv/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchtext.datasets import SST2\n",
        "\n",
        "# Carica il dataset\n",
        "train_data, test_data = SST2(\n",
        "    root=\"data/db\",\n",
        "    split='train',\n",
        "), SST2(\n",
        "    root=\"data/db\",\n",
        "    split='test',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from source.MachineUnlearning import train\n",
        "\n",
        "train(\n",
        "    model,\n",
        "    loader,\n",
        "    10,\n",
        "    n_layers=2,\n",
        "    w=0.1,   # the weight of the unlearning term (1% of the classification loss)\n",
        "    device=torch.device('cuda'),\n",
        "    classes=list_classes,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from source.MachineUnlearning import test\n",
        "\n",
        "test(\n",
        "    model,\n",
        "    test_loader,\n",
        "    device=torch.device('cuda'),\n",
        "    classes=list_classes,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
