{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Unlearning\n",
        "\n",
        "Can you unlearn something?\n",
        "\n",
        "Your task here is the following: given a network pre-trained on some data, you want to finetune it to selectively forget a class, and learn a new class.\n",
        "\n",
        "As an initial approach, you may do the following.\n",
        "\n",
        "Start with a MNIST classifier pre-trained on a subset of the\n",
        "digits.\n",
        "\n",
        "Now replace one of the learned digits, say the class \u201c6\u201d, with a new digit, say \u201c3\u201d.\n",
        "\n",
        "A possible way to proceed is to identify which weights are more involved in the prediction of class \u201c6\u201d, freeze all the rest, and train with a loss that favors the \u201c3\u201d while penalizing the \u201c6\u201d.\n",
        "\n",
        "Test this baseline and see whether it brings you anywhere. Are there any pitfalls in this idea? Does it work? Use it as a first line of attack to understand the problem.\n",
        "\n",
        "Starting from these baseline tests, devise a new unlearning procedure.\n",
        "\n",
        "You can improve upon this baseline, make up your own idea from scratch, or check the literature to get ideas.\n",
        "\n",
        "If you use an existing approach, you must add something new, for example by testing it on some new data modality (e.g., audio), by studying more extreme cases, failures, weaknesses, or by making it more efficient, and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HOW TO TRAIN A MODEL\n",
        "\n",
        "# select a template from source.template:\n",
        "from source.template.EMNIST import main\n",
        "main(20, 10, 256, 'data/models/EMNIST')\n",
        "\n",
        "#from source.template.Cifar10 import main\n",
        "#main(8, 30, 512, 'data/models/Cifar10')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load EMNIST template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LOAD A MODEL\n",
        "import torch\n",
        "import os\n",
        "from source.template.EMNIST import Classifier\n",
        "from source.template.EMNIST import N_CLASSES\n",
        "import random\n",
        "\n",
        "model_path = \"data/models/EMNIST/36_41_15_32_20_40_12_14_17_13_37_18_3_5_35_11_23_16_1_39.pt\"\n",
        "original_list_classes = [int(c) for c in os.path.splitext(os.path.basename(model_path))[0].split('_')]\n",
        "n_classes = len(original_list_classes)\n",
        "\n",
        "model = Classifier(n_classes)\n",
        "model.load_state_dict(torch.load(model_path, weights_only=True))\n",
        "\n",
        "# seleziono una old_class a caso da list_classes\n",
        "old_class = random.choice(original_list_classes)\n",
        "# ottengo la new_class (un numero in range(N_CLASSES) non in list_classes)\n",
        "new_class = random.choice([i for i in range(N_CLASSES) if i not in original_list_classes])\n",
        "# sostituisco old_class con new_class in list_classes\n",
        "list_classes = original_list_classes.copy()\n",
        "list_classes[list_classes.index(old_class)] = new_class\n",
        "\n",
        "print(\"Classi originali:      \", original_list_classes)\n",
        "print(\"Classi da memorizzare: \", list_classes)\n",
        "print(\"Classi da dimenticare: \", old_class, f\" (sostituita da {new_class})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAKE DATALOADER\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from source.template.EMNIST import SPLIT, FilterSet\n",
        "\n",
        "loader = torch.utils.data.DataLoader(\n",
        "    FilterSet(\n",
        "        torchvision.datasets.EMNIST(\n",
        "            root=\"data/db\",\n",
        "            split=SPLIT,\n",
        "            train=True,\n",
        "            download=True,\n",
        "            transform=transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Grayscale(),\n",
        "                    transforms.Pad(2),  # pad to 32x32\n",
        "                    transforms.RandomAffine(\n",
        "                        degrees=5,\n",
        "                        translate=(0.1, 0.1),\n",
        "                        scale=(0.9, 1.1),\n",
        "                        shear=10\n",
        "                    ),\n",
        "                    transforms.ColorJitter(contrast=(0.9,1.5)),\n",
        "                ]\n",
        "            ),\n",
        "            target_transform=lambda x: list_classes.index(x) if x in list_classes else -1\n",
        "        ),\n",
        "        torch.tensor(list_classes + [old_class]),\n",
        "    ),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TEST LOADER\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    FilterSet(\n",
        "        torchvision.datasets.EMNIST(\n",
        "            root=\"data/db\",\n",
        "            split=SPLIT,\n",
        "            train=False,\n",
        "            download=True,\n",
        "            transform=transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Grayscale(),\n",
        "                    transforms.Pad(2),  # pad to 32x32\n",
        "                ]\n",
        "            ),\n",
        "            target_transform=lambda x: list_classes.index(x) if x in list_classes else -1\n",
        "        ),\n",
        "        torch.tensor(list_classes + [old_class]),\n",
        "    ),\n",
        "    batch_size=512,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Cifar10 template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LOAD A MODEL\n",
        "import torch\n",
        "import os\n",
        "from source.template.Cifar10 import Classifier\n",
        "from source.template.Cifar10 import N_CLASSES\n",
        "import random\n",
        "\n",
        "model_path = \"data/models/Cifar10/7_5_8_1_9_6_2_3.pt\"\n",
        "original_list_classes = [int(c) for c in os.path.splitext(os.path.basename(model_path))[0].split('_')]\n",
        "n_classes = len(original_list_classes)\n",
        "\n",
        "model = Classifier(n_classes)\n",
        "model.load_state_dict(torch.load(model_path, weights_only=True))\n",
        "\n",
        "# seleziono una old_class a caso da list_classes\n",
        "old_class = random.choice(original_list_classes)\n",
        "# ottengo la new_class (un numero in range(N_CLASSES) non in list_classes)\n",
        "new_class = random.choice([i for i in range(N_CLASSES) if i not in original_list_classes])\n",
        "# sostituisco old_class con new_class in list_classes\n",
        "list_classes = original_list_classes.copy()\n",
        "list_classes[list_classes.index(old_class)] = new_class\n",
        "\n",
        "print(\"Classi originali:      \", original_list_classes)\n",
        "print(\"Classi da memorizzare: \", list_classes)\n",
        "print(\"Classi da dimenticare: \", old_class, f\" (sostituita da {new_class})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MAKE DATALOADER\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from source.template.Cifar10 import FilterSet\n",
        "\n",
        "loader = torch.utils.data.DataLoader(\n",
        "    FilterSet(\n",
        "        torchvision.datasets.CIFAR10(\n",
        "            root=\"data/db\",\n",
        "            train=True,\n",
        "            download=True,\n",
        "            transform=transforms.Compose([\n",
        "                transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
        "                transforms.RandomAffine(\n",
        "                    degrees=0,\n",
        "                    scale=(1.0, 1.1),\n",
        "                    shear=0\n",
        "                ),\n",
        "                transforms.ColorJitter(\n",
        "                    contrast=(0.9,1.5),\n",
        "                    saturation=(0.9,1.3),\n",
        "                    brightness=(0.9,1.3),\n",
        "                    hue=(-0.05,0.05),\n",
        "                ),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
        "            ]),\n",
        "            target_transform=lambda x: list_classes.index(x) if x in list_classes else -1\n",
        "        ),\n",
        "        torch.tensor(list_classes + [old_class]),\n",
        "    ),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TEST LOADER\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    FilterSet(\n",
        "        torchvision.datasets.CIFAR10(\n",
        "            root=\"data/db\",\n",
        "            train=False,\n",
        "            download=True,\n",
        "            transform=transforms.Compose(\n",
        "                [\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
        "                ]\n",
        "            ),\n",
        "            target_transform=lambda x: list_classes.index(x) if x in list_classes else -1\n",
        "        ),\n",
        "        torch.tensor(list_classes + [old_class]),\n",
        "    ),\n",
        "    batch_size=512,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from source.MachineUnlearning import train\n",
        "\n",
        "train(\n",
        "    model,\n",
        "    loader,\n",
        "    10,\n",
        "    n_layers=2,\n",
        "    w=0.1,   # the weight of the unlearning term (1% of the classification loss)\n",
        "    device=torch.device('cuda'),\n",
        "    classes=list_classes,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from source.MachineUnlearning import test\n",
        "\n",
        "test(\n",
        "    model,\n",
        "    test_loader,\n",
        "    device=torch.device('cuda'),\n",
        "    classes=list_classes,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
